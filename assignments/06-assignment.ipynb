{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DATASCI 350: Data Science Computing\n",
                "\n",
                "## Assignment 06 - AI & Prompt Engineering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Instructions\n",
                "\n",
                "In this assignment, you will explore prompt engineering techniques using Large Language Models (LLMs). You can use any LLM of your choice (ChatGPT, Claude, Gemini, etc.) unless a specific tool is mentioned.\n",
                "\n",
                "For each question:\n",
                "- Document your prompts and the model's responses\n",
                "- Include screenshots where helpful\n",
                "- Clearly label your answers with the question number\n",
                "\n",
                "As always, should you have any questions, please let me know.\n",
                "\n",
                "### Tasks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 1: Tokenisation Analysis**\n",
                "\n",
                "Using OpenAI's tokeniser (https://platform.openai.com/tokenizer), compare token counts for the following three phrases:\n",
                "- English: \"Hello, world!\"\n",
                "- Chinese: \"你好，世界！\"\n",
                "- Arabic: \"مرحبا بالعالم!\"\n",
                "\n",
                "a) Report the token count for each phrase.\n",
                "\n",
                "b) Explain the implications for API costs when working with multilingual data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 2: Embedding Analogies**\n",
                "\n",
                "The lecture shows the famous example: \"king − man + woman ≈ queen\" as vector arithmetic with embeddings.\n",
                "\n",
                "a) Explain why this works based on how embeddings capture semantic relationships.\n",
                "\n",
                "b) Propose two other analogies that might work (e.g., country:capital, verb:past_tense) and explain your reasoning."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 3: PTCF Framework**\n",
                "\n",
                "Rewrite this vague prompt using the PTCF framework (Persona, Task, Context, Format) for two different personas:\n",
                "\n",
                "**Original prompt:** \"Tell me about climate change\"\n",
                "\n",
                "**Persona 1:** A climate scientist briefing policymakers  \n",
                "**Persona 2:** A secondary school teacher creating lesson materials\n",
                "\n",
                "For each rewrite, clearly label the Persona, Task, Context, and Format components."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 4: Format Specification**\n",
                "\n",
                "Test extracting information from the following text:\n",
                "\n",
                "> \"Tesla Q4 2024 reports $25.7B revenue, beating estimates by 2%. EPS missed by 6%. Vehicle deliveries reached 495,000 units.\"\n",
                "\n",
                "a) Write a prompt that outputs JSON with a specified schema (define your own schema with at least 4 fields).\n",
                "\n",
                "b) Write a prompt that outputs a Markdown table with the same information.\n",
                "\n",
                "Compare the results: which format is more consistent for automated processing?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 5: Temperature Experiment**\n",
                "\n",
                "Using Google AI Studio (https://ai.google.dev/aistudio) or another tool that allows temperature control, run this prompt at temperatures 0.0, 0.5, and 1.0:\n",
                "\n",
                "> \"Write a two-paragraph opening for a mystery novel set in Tokyo.\"\n",
                "\n",
                "a) Document the outputs at each temperature setting.\n",
                "\n",
                "b) For what types of tasks would you use each temperature setting? Give one example for each."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 6: Meta-Prompting**\n",
                "\n",
                "You want to classify customer support tickets into four categories: Billing, Technical, Account, and Other.\n",
                "\n",
                "Write an initial prompt for this task, then ask the LLM: \"What's unclear about this prompt? How would you improve it?\"\n",
                "\n",
                "a) Document your original prompt and the LLM's suggestions.\n",
                "\n",
                "b) Write a revised prompt incorporating the feedback."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 7: Meta-Prompt Creation**\n",
                "\n",
                "Create your own meta-prompt to help you design better prompts. Your meta-prompt should ask the LLM to help you craft an effective prompt for a specific task.\n",
                "\n",
                "a) Write a meta-prompt that asks the LLM something like: \"I want to [accomplish X task]. What questions should I ask you to get the best results? What information should I provide in my prompt?\"\n",
                "\n",
                "Choose one of these tasks:\n",
                "- Summarising research papers\n",
                "- Generating code documentation\n",
                "- Analysing customer feedback\n",
                "\n",
                "b) Test the prompt that the LLM helps you create and document whether it produces better results than a naïve first attempt."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 8: Scientific Literature and Hallucination**\n",
                "\n",
                "Ask an LLM to provide 3 peer-reviewed scientific articles about the following topic:\n",
                "\n",
                "> \"The effects of sleep deprivation on cognitive performance in adults.\"\n",
                "\n",
                "Request that the LLM provide for each article: the authors, title, journal name, year of publication, and DOI.\n",
                "\n",
                "a) Document the LLM's response and verify if the citations are real by checking Google Scholar or the DOI links.\n",
                "\n",
                "b) What percentage of citations were accurate? How would you design a prompt to reduce hallucinated citations?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 9: Few-Shot Example Selection**\n",
                "\n",
                "The lecture states that examples should represent \"the hardest cases, not average cases.\" Test this claim.\n",
                "\n",
                "Compare two few-shot prompts for sentiment classification. Test both on these 3 challenging sentences:\n",
                "- \"Not as bad as I expected, actually.\"\n",
                "- \"Would have been great if not for the noise.\"\n",
                "- \"It's okay I guess.\"\n",
                "\n",
                "**Prompt A (Naïve examples):**\n",
                "```\n",
                "Classify the sentiment as Positive, Negative, or Neutral.\n",
                "Examples:\n",
                "- \"I love it!\" → Positive\n",
                "- \"I hate it!\" → Negative\n",
                "```\n",
                "\n",
                "**Prompt B (Edge-case examples):**\n",
                "```\n",
                "Classify the sentiment as Positive, Negative, or Neutral.\n",
                "Examples:\n",
                "- \"Could have been worse\" → Negative\n",
                "- \"Decent but overpriced\" → Negative\n",
                "- \"Nothing special but gets the job done\" → Neutral\n",
                "```\n",
                "\n",
                "a) Document results from both prompts on all 3 test sentences.\n",
                "\n",
                "b) Which prompt performed better on ambiguous cases? Why?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question 10: System Prompt Design**\n",
                "\n",
                "Design a system prompt for an AI assistant that helps students check their essays for grammar and clarity. The assistant should:\n",
                "- Be encouraging but honest\n",
                "- Point out specific issues with examples\n",
                "- Never write content for the student\n",
                "\n",
                "a) Write the system prompt.\n",
                "\n",
                "b) Test it with this sample essay excerpt and document the response:\n",
                "\n",
                "> \"Their are many reasons why climate change is important. First of all its affecting everyone. The weather is getting more worser every year and scientist say we need to act now. In conclusion, we all need to do more.\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}